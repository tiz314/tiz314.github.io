---
layout: post
title: Fighting Imbalance: Classifying SSH Honeypot Attacks
permalink: /sshattacks
---

The project explores techniques to classify SSH sessions—sequences of executed commands—according to the MITRE ATT&CK framework. This work starts as an academic exercise for the Cybersecurity Engineering MSc @ PoliTo for the Machine Learning for Networking course, to see how simple Machine Learning methods behave on a non-trivial, noisy task.

While not intended as a state-of-the-art benchmark, it offers interesting insights into data cleaning and model selection. The project is a collaboration between @[Tiz314](https://github.com/Tiz314) @[Rebel-Nightmare](https://github.com/Rebel-Nightmare), @[kuzeykara](https://github.com/kuzeykara), and @[emirakincy](https://github.com/emirakinci).

### The Challenge: Classifying Intent
Each SSH session contains subsets of commands that map to specific intents: **Discovery**, **Defense Evasion**, **Execution**, **Persistence**, **Impact**, or simply **Harmless** activity.

The major hurdle is the dataset itself. It contains massive amounts of duplicated data generated by automated scripts. Attackers often run the same scripts repeatedly in short intervals, changing only obfuscated payloads or adding pseudo-random strings to evade detection.

For example, consider this session labelled as `['Discovery', 'Persistence']`:
```bash
cat /proc/cpuinfo | grep name | wc -l ; echo -e ""nSnb92bRBPJR7"
```

Because a single session can exhibit multiple behaviours, we treat this as a **Multi-Label Classification** problem. We assume labels are independent Bernoulli trials since the original labelling is based on specific substrings rather than the session as a whole. This leads to counterintuitive but necessary combinations, where a session can be both `Harmless` (containing `ls`, `cd`) and `Discovery` (containing `grep`, `cat`) simultaneously.

### Pre-processing: Aggressive Cleaning
First things first: the dataset needs polishing. In its original form, it comprises over 230,000 samples, but the vast majority are semantic duplicates.

Our approach is to generalize the sessions to reveal their true structure:
* **De-obfuscation:** Pseudo-random strings are removed.
* **Placeholders:** Instance-specific data like IP addresses are replaced with `<IPV4>`/`<IPV6>`, and passwords becomes `<PASSWORD>`.
* **Payloads:** HEX and Base64 blobs are replaced with generic placeholders like `<B64>`. While decoding them might reveal more info, we stick to the original text to maintain consistency with how the ground-truth labels are generated.

This aggressive cleaning reduces the dataset size from **~233,000** raw entries to just **1,952 unique semantic samples**.

### Classification Results
For the modelling phase, each sample is vectorized using TF-IDF to penalize generic command syntax (like `grep` or `echo`) and highlight rare, discriminative flags.

The class distribution remains highly imbalanced. **Discovery** and **Persistence** sessions dominate the dataset, while **Impact** sessions are incredibly rare. This imbalance persists after pre-processing, making it difficult for models to learn the minority classes.

We experiment with several approaches:
* **Naive Bayes:** This results in high bias and underfitting, struggling to capture the complexity of the data.
* **Linear SVM:** This performs significantly better. After hyperparameter tuning, it reaches an exact match accuracy of **83%** and a solid F1-Score macro average.

### Unsupervised Learning & Transformers
We also run clustering experiments to analyze how sessions group naturally. Using **DBSCAN**, we find that distinct "sub-techniques" exist within major clusters. For instance, we identify a specific "Polymorphic Credential Modification" campaign where attackers rotate passwords in every session.

Finally, we experiment with **BERT**, adding a final dense layer for fine-tuning. Surprisingly, it underperforms compared to the simpler Linear SVM. We suspect this is due to two factors:
1.  **Small Data:** The cleaned dataset (approx. 2000 samples) is likely too small for such a complex model.
2.  **Token Limit:** BERT's 512-token limit means we have to truncate long logs, potentially losing the specific commands that triggered the label.

Future research would likely need models pre-trained specifically on code or command-line logs, rather than standard English text.