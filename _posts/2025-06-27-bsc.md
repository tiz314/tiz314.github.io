---
layout: post
title: Integration of Large Language Models for Decision Support in Security Assurance
permalink: /bsc
---

*University of Milan*  
*Bachelor’s Degree in Security of Systems and Computer Networks*  
*Academic Year 2024/2025*  

This post summarizes problems, objectives, solutions, evaluations, and conclusions of my BSc thesis.

## SESARlab

SESARlab conducts research in the fields of *Cloud Computing* and service-oriented architectures. A key focus is the implementation of *Security Assurance*—the justifiable guarantee that a system is adequately protected and operational, ensured through continuously implemented and verified controls.

The internship was conducted in collaboration with the development team behind the **Moon Cloud** platform, which aims to provide Security Assurance for distributed systems.

## Initial Context

Moon Cloud is a *Platform as a Service (PaaS)* platform where controls are implemented via scripts (probes) that take as input a set of configuration data necessary for their execution. The platform’s objective is to ensure *compliance* with standards and regulations (e.g., GDPR or HIPAA).

Currently, the selection and configuration of probes is a manual, repetitive, and error-prone process—especially when dealing with regulatory compliance. Operators must be familiar with the full list of available probes and their characteristics to select the appropriate ones for specific controls required by regulations.

## Project Objectives

The main goal of this work was to assess the feasibility of using **Large Language Models (LLMs)** to automate the selection and configuration of probes. The aim was to develop a **Decision Support System (DSS)** that eases the operator’s workload.

The research was divided into three phases:
1. Designing the DSS,
2. Developing a supporting methodology,
3. Evaluating performance through a developed **Proof-of-Concept (PoC)**.

A central element of the study was the use of **compact open-source models** as alternatives to large commercial ones, in pursuit of economic sustainability and greater control over data confidentiality.

This work fits into the broader context of applying LLMs in decision support systems, previously explored in fields such as medicine, economics, cybersecurity, and regulatory compliance. Unlike previous studies, this project proposed a **systematic approach** to automated control selection for Security Assurance, offering an alternative to limitations identified in the literature.

## Work Performed

The preliminary phase involved studying the anatomy of probes and developing a suite of controls for auditing the MQTT broker **VerneMQ**, enriching the catalog used in subsequent phases.

An architecture was then designed in which the user submits requests through a dashboard. The system generates a **prompt** using a template and a catalog of probes, applying *In-Context Retrieval Augmented Generation (RAG)* techniques. For each selected control, the same process is repeated for probe configuration. The operator is thus provided with a set of proposed and pre-configured controls.

A methodology was developed that includes:
- (i) classification of user requests;
- (ii) management of information required for generation;
- (iii) types and design of prompts;
- (iv) task-specific prompts for selection and configuration;
- (v) support for security frameworks, including extensions to probe documentation standards;
- (vi) performance evaluation tools, including a dataset classification system and evaluation metrics.

Improvement strategies focused on **prompt engineering** rather than tuning model parameters, as the latter showed limitations in keeping up with knowledge updates.

Challenges included dataset generation and the need for a **human-in-the-loop** approach to evaluation. The evaluation was based on a **walkthrough** that demonstrated the variability in performance as a function of prompt engineering techniques. Results showed that outputs could increasingly approximate ideal outcomes solely through input manipulation.

A second **qualitative evaluation** employed an *LLM-as-a-judge* approach: a more powerful model was used to assess results generated using prompts with varying levels of detail. This demonstrated that performance can indeed be improved for specific tasks using a lightweight model—without any need to fine-tune its parameters.

A Python-based PoC was developed for this purpose, accessible via API and web interface, and hosted on a GPU-powered virtual machine within the lab.

Finally, integration scenarios with Moon Cloud were partially explored to enable automated deployment of selected controls. Potential vulnerabilities (e.g., *prompt hacking*) were analyzed, and recommendations were made to update the platform’s threat model.

## Future Developments and Conclusions

Future work will focus on dataset generation and official benchmarking, searching for more performant open-source models, experimenting with different prompts, and improving support for standards. Another promising direction is **fine-tuning models** to integrate domain-specific cybersecurity knowledge, followed by performance analysis.

Full integration with Moon Cloud is also a key goal, enabling **automated deployment** of selected probes.

The proposed solution has laid the foundation for future applications and proved its effectiveness, while acknowledging the continued importance of expert oversight in evaluating the generated results.
