---
layout: post
title: Integration of Large Language Models for Decision Support in Security Assurance
permalink: /bsc
---

*University of Milan*  
*Bachelor’s Degree in Security of Systems and Computer Networks*  
*Academic Year 2024/2025*  

This post summarizes problems, objectives, solutions, evaluations, and conclusions of my BSc thesis developed at the SEcure Service-oriented Architecture Research Lab (SESARlab).

## SESARlab

The laboratory conducts research in the field of Cloud Computing and service-oriented architectures. Of particular interest is the implementation of Security Assurance, namely the justifiable guarantee that a system is adequately protected and operational through continuously implemented and verified controls. The internship was carried out in collaboration with the development team of the Moon Cloud platform, aimed at achieving Security Assurance for distributed systems.

## Initial Context

Moon Cloud is a Platform as a Service (PaaS) platform where controls are implemented through scripts (probes) that receive as input a list of data required for their execution (configuration). The platform's goal is to provide compliance with standards and regulations (e.g., GDPR or HIPAA). Currently, the selection and configuration of probes is manual, repetitive, and prone to errors, especially in cases of regulatory compliance. Operators are required to know all available probes and their characteristics, needing to select the appropriate probes for specific technical regulation controls.

## Work Objectives

The main objective is to evaluate the feasibility of using generative language models (LLMs) to automate the selection and configuration of probes by developing a Decision Support System (DSS) that reduces operator workload. The research is divided into four phases: (i) design of the DSS; (ii) development of a supporting framework; (iii) performance evaluation; and (iv) development of a proof-of-concept (PoC) with a graphical interface.

A central element of the study is the use of compact open-source models as an alternative to large commercial models, pursuing goals of economic sustainability and greater control over data confidentiality.

The study fits within the context of LLM applications in decision support systems, already explored in fields such as medicine, economics, cybersecurity, and regulatory compliance. Unlike these studies, it proposes for the first time a systematic approach to automated selection of controls for Security Assurance, offering alternative solutions to limitations found in part of the existing literature.

## Work Carried Out

A preliminary phase involved studying the anatomy of the probes and developing a suite of checks for the VerneMQ MQTT broker, enriching the catalog used in later phases.

An architecture was then defined in which the user submits requests through a dashboard, the system composes a prompt based on a template and a probe catalog, applying In-Context Retrieval Augmented Generation (In-Context RAG) techniques. For each selected control, the process is repeated for the probe configuration phase. The operator thus receives a suite of proposed and pre-configured controls.

Subsequently, a framework of rules and tools was defined for: (i) classification of requests the operator may submit; (ii) types and design of prompts; (iii) management of information needed for generation; (iv) prompts defined for different tasks; (v) support for security frameworks and a new structure for probe documentation; (vi) tools for performance evaluation, including a dataset classification system and metrics.

Improvement strategies were analyzed, focusing on prompt engineering rather than modifying model parameters. The latter approach showed limitations with respect to the phenomenon of continuous knowledge updates.

Issues related to dataset generation and the need for a human-in-the-loop approach in result evaluation were analyzed. The proposed evaluation was thus based on a walkthrough representative of performance variability in response to prompt engineering techniques.

A second qualitative evaluation was based on an LLM-as-a-judge approach: starting from a dataset generated following the framework rules, a more capable model was used to evaluate the results obtained using prompts with different levels of information, demonstrating that it is indeed possible to improve responses for a specific task using a compact model and especially without altering parameters.

Finally, a PoC in Python was developed, accessible via a web app, hosted on the lab's GPU VM.

Marginally, scenarios of full integration with Moon Cloud were addressed to offer automation in deploying the selected controls. Possible vulnerabilities (e.g., prompt hacking) were analyzed, highlighting some potential issues and suggesting an update to the platform’s threat model.

## Future Developments and Conclusions

Future developments will concern dataset generation and execution of official benchmarks, the search for more performant open-source models, the improvement of prompts and support for standards. Finally, separate from the DSS, a system is proposed for forecasting assurance through time series analysis.

In conclusion, the internship was a valuable opportunity to explore the operation and use of a new technology with a scientific approach. It laid the foundation for future applications and confirmed the validity of the approach, while recognizing the need for an expert to evaluate the results.
